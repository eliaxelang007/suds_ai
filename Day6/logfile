DEBUG [2024-08-30 16:21:10] urllib3.connectionpool - Starting new HTTPS connection (1): api.smith.langchain.com:443
WARNING [2024-08-30 16:21:10] langchain_core.callbacks.base - CallbackManager.merge(): Parent run IDs do not match. Using the parent run ID of the first callback manager.
DEBUG [2024-08-30 16:21:10] openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'You are a research assistant who can search for up-to-date info using the Tavily search engine.\nWork autonomously according to your specialty\nusing the tools available to you.\nDo not ask for clarification.\n\nYour other team members and other teams will collaborate with you\nwith their own specialties.\n\nYou are one of: search', 'role': 'system'}, {'content': "What are the main takeaways from the paper `Extending Llama-3's Context Ten-Fold Overnight'?", 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}}]}}
DEBUG [2024-08-30 16:21:10] openai._base_client - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
DEBUG [2024-08-30 16:21:10] httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
DEBUG [2024-08-30 16:21:10] httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D01BBE2CF0>
DEBUG [2024-08-30 16:21:10] httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D0170A1B50> server_hostname='api.openai.com' timeout=None
DEBUG [2024-08-30 16:21:10] httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D01BBE2C00>
DEBUG [2024-08-30 16:21:10] httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
DEBUG [2024-08-30 16:21:10] httpcore.http11 - send_request_headers.complete
DEBUG [2024-08-30 16:21:10] httpcore.http11 - send_request_body.started request=<Request [b'POST']>
DEBUG [2024-08-30 16:21:10] httpcore.http11 - send_request_body.complete
DEBUG [2024-08-30 16:21:10] httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
DEBUG [2024-08-30 16:21:10] urllib3.connectionpool - https://api.smith.langchain.com:443 "GET /info HTTP/11" 200 455
DEBUG [2024-08-30 16:21:10] urllib3.connectionpool - https://api.smith.langchain.com:443 "POST /runs/batch HTTP/11" 202 33
DEBUG [2024-08-30 16:21:11] httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 30 Aug 2024 08:21:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-dk2njyfqbl68x2tbxw0vnucl'), (b'openai-processing-ms', b'529'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199877'), (b'x-ratelimit-reset-requests', b'15.045s'), (b'x-ratelimit-reset-tokens', b'36ms'), (b'x-request-id', b'req_7bdee630b434a641178a0a41833104bb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ks9g4bDOWf2xkddn7yM8s5XGVmJ.BfQ2LVVz6UgwAyw-1725006069-1.0.1.1-ir8bZm5eAthV50T1FpdkjhhiT5CDQU1E3Ux2q4ujxJfPRtLsuxMb9zwLF3EA2I4VCWO5FNt1R7xyWLkBBdqZAg; path=/; expires=Fri, 30-Aug-24 08:51:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Z1x_2UlBpYduMGDo4gwrzCQdX69rj38uHZOD_..7lFc-1725006069178-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8bb35d96fd81807e-NRT'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
INFO [2024-08-30 16:21:11] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG [2024-08-30 16:21:11] httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
DEBUG [2024-08-30 16:21:11] httpcore.http11 - receive_response_body.complete
DEBUG [2024-08-30 16:21:11] httpcore.http11 - response_closed.started
DEBUG [2024-08-30 16:21:11] httpcore.http11 - response_closed.complete
DEBUG [2024-08-30 16:21:11] openai._base_client - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 30 Aug 2024 08:21:09 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-dk2njyfqbl68x2tbxw0vnucl'), ('openai-processing-ms', '529'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=15552000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9998'), ('x-ratelimit-remaining-tokens', '199877'), ('x-ratelimit-reset-requests', '15.045s'), ('x-ratelimit-reset-tokens', '36ms'), ('x-request-id', 'req_7bdee630b434a641178a0a41833104bb'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Ks9g4bDOWf2xkddn7yM8s5XGVmJ.BfQ2LVVz6UgwAyw-1725006069-1.0.1.1-ir8bZm5eAthV50T1FpdkjhhiT5CDQU1E3Ux2q4ujxJfPRtLsuxMb9zwLF3EA2I4VCWO5FNt1R7xyWLkBBdqZAg; path=/; expires=Fri, 30-Aug-24 08:51:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=Z1x_2UlBpYduMGDo4gwrzCQdX69rj38uHZOD_..7lFc-1725006069178-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8bb35d96fd81807e-NRT'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
DEBUG [2024-08-30 16:21:11] openai._base_client - request_id: req_7bdee630b434a641178a0a41833104bb
DEBUG [2024-08-30 16:21:11] urllib3.connectionpool - Starting new HTTPS connection (1): api.tavily.com:443
DEBUG [2024-08-30 16:21:11] urllib3.connectionpool - https://api.smith.langchain.com:443 "POST /runs/batch HTTP/11" 202 33
DEBUG [2024-08-30 16:21:14] urllib3.connectionpool - https://api.tavily.com:443 "POST /search HTTP/11" 200 2735
DEBUG [2024-08-30 16:21:14] openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'You are a research assistant who can search for up-to-date info using the Tavily search engine.\nWork autonomously according to your specialty\nusing the tools available to you.\nDo not ask for clarification.\n\nYour other team members and other teams will collaborate with you\nwith their own specialties.\n\nYou are one of: search', 'role': 'system'}, {'content': "What are the main takeaways from the paper `Extending Llama-3's Context Ten-Fold Overnight'?", 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_1bDnoTTqO47HoPmb5XwSf4lW', 'function': {'name': 'tavily_search_results_json', 'arguments': '{"query": "Extending Llama-3\'s Context Ten-Fold Overnight paper main takeaways"}'}}]}, {'content': '[{"url": "https://arxiv.org/abs/2404.19553", "content": "View a PDF of the paper titled Extending Llama-3\'s Context Ten-Fold Overnight, by Peitian Zhang and 6 other authors. We extend the context length of Llama-3-8B-Instruct from 8K to 80K via QLoRA fine-tuning. The entire training cycle is super efficient, which takes 8 hours on one 8xA800 (80G) GPU machine. The resulted model exhibits superior ..."}, {"url": "https://dev.to/mikeyoung44/extending-llama-3s-context-ten-fold-overnight-4340", "content": "This is a Plain English Papers summary of a research paper called Extending Llama-3\'s Context Ten-Fold Overnight.If you like these kinds of analysis, you should subscribe to the AImodels.fyi newsletter or follow me on Twitter.. Overview Extends the context length of Llama-3-8B-Instruct model from 8K to 80K via QLoRA fine-tuning"}, {"url": "https://vladbogo.substack.com/p/extending-llama-3s-context-ten-fold", "content": "The authors demonstrate an efficient way to extend an LLM\'s context length up to 80K tokens, while retaining decent performance on long contexts. For more information please consult the full paper. Congrats to the authors for their work! Zhang, Peitian, et al. \\"Extending Llama-3\'s Context Ten-Fold Overnight.\\""}, {"url": "https://arxiv.org/pdf/2404.19553", "content": "Extending Llama-3\'s Context Ten-Fold Overnight Peitian Zhang 1,2, Ninglu Shao , Zheng Liu \\u2217, Shitao Xiao 1, Hongjin Qian,2, Qiwei Ye1, Zhicheng Dou2 1 Beijing Academy of Artificial Intelligence 2 Gaoling School of Artificial Intelligence, Renmin University of China namespace.pt@gmail.com zhengliu1026@gmail.com Abstract We extend the context length of Llama-3-8B-Instruct from 8K to 80K via ..."}, {"url": "https://paperswithcode.com/paper/extending-llama-3-s-context-ten-fold/review/", "content": "Extending Llama-3\'s Context Ten-Fold Overnight . We extend the context length of Llama-3-8B-Instruct from 8K to 80K via QLoRA fine-tuning. The entire training cycle is super efficient, which takes 8 hours on one 8xA800 (80G) GPU machine."}]', 'role': 'tool', 'tool_call_id': 'call_1bDnoTTqO47HoPmb5XwSf4lW'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}}]}}
DEBUG [2024-08-30 16:21:14] openai._base_client - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
DEBUG [2024-08-30 16:21:14] httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
DEBUG [2024-08-30 16:21:14] httpcore.http11 - send_request_headers.complete
DEBUG [2024-08-30 16:21:14] httpcore.http11 - send_request_body.started request=<Request [b'POST']>
DEBUG [2024-08-30 16:21:14] httpcore.http11 - send_request_body.complete
DEBUG [2024-08-30 16:21:14] httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
DEBUG [2024-08-30 16:21:15] urllib3.connectionpool - https://api.smith.langchain.com:443 "POST /runs/batch HTTP/11" 202 33
DEBUG [2024-08-30 16:21:16] httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 30 Aug 2024 08:21:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-dk2njyfqbl68x2tbxw0vnucl'), (b'openai-processing-ms', b'1164'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199362'), (b'x-ratelimit-reset-requests', b'19.178s'), (b'x-ratelimit-reset-tokens', b'191ms'), (b'x-request-id', b'req_a6cd1a278b8e8f2149052835d240ffe4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8bb35db30b01807e-NRT'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
INFO [2024-08-30 16:21:16] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG [2024-08-30 16:21:16] httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
DEBUG [2024-08-30 16:21:16] httpcore.http11 - receive_response_body.complete
DEBUG [2024-08-30 16:21:16] httpcore.http11 - response_closed.started
DEBUG [2024-08-30 16:21:16] httpcore.http11 - response_closed.complete
DEBUG [2024-08-30 16:21:16] openai._base_client - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 30 Aug 2024 08:21:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-dk2njyfqbl68x2tbxw0vnucl', 'openai-processing-ms': '1164', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '199362', 'x-ratelimit-reset-requests': '19.178s', 'x-ratelimit-reset-tokens': '191ms', 'x-request-id': 'req_a6cd1a278b8e8f2149052835d240ffe4', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8bb35db30b01807e-NRT', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
DEBUG [2024-08-30 16:21:16] openai._base_client - request_id: req_a6cd1a278b8e8f2149052835d240ffe4
DEBUG [2024-08-30 16:21:16] urllib3.connectionpool - https://api.smith.langchain.com:443 "POST /runs/batch HTTP/11" 202 33
DEBUG [2024-08-30 16:21:16] langsmith.client - Closing Client.session
DEBUG [2024-08-30 16:21:16] langsmith.client - Closing Client.session
