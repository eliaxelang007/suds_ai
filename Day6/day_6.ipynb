{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from typing import Annotated, Any, Callable\n",
    "\n",
    "from enum import StrEnum\n",
    "from operator import itemgetter\n",
    "# from pprint import pprint\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "from pydantic.v1 import SecretStr\n",
    "from tiktoken import encoding_for_model\n",
    "\n",
    "from logging import basicConfig, DEBUG\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_core.tools import BaseTool, tool # pyright: ignore [reportUnknownVariableType]\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, Runnable\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.prebuilt.chat_agent_executor import ToolExecutor, AgentState, create_react_agent # pyright: ignore [reportUnknownVariableType, reportMissingTypeStubs]\n",
    "from langgraph.graph import END, StateGraph # pyright: ignore [reportMissingTypeStubs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script\n",
    "\n",
    "def clean_multi_line(text: str) -> str:\n",
    "    return \"\\n\".join(\n",
    "        line.strip() for\n",
    "        line in\n",
    "        text\n",
    "            .strip()\n",
    "            .split(\"\\n\")\n",
    "    )\n",
    "\n",
    "def create_vectorstore(documents: list[Document]) -> VectorStoreRetriever:\n",
    "    def chunk() -> list[Document]:\n",
    "        gpt_3_4_turbo_encoding = encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "        def token_len(text: str) -> int:\n",
    "            return len(gpt_3_4_turbo_encoding.encode(text))\n",
    "\n",
    "        return RecursiveCharacterTextSplitter(\n",
    "            chunk_size=300,\n",
    "            chunk_overlap=0,\n",
    "            length_function=token_len\n",
    "        ).split_documents(\n",
    "            documents\n",
    "        )\n",
    "\n",
    "    return Qdrant.from_documents(\n",
    "        chunk(),\n",
    "        OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "        location=\":memory:\",\n",
    "        collection_name=\"llama_3_paper\"\n",
    "    ).as_retriever()\n",
    "\n",
    "def get_api_key(key_name: str) -> str:\n",
    "    ENVIRONMENT_SECRETS = \"environment_secrets\"\n",
    "\n",
    "    if not hasattr(get_api_key, ENVIRONMENT_SECRETS):\n",
    "        setattr(get_api_key, ENVIRONMENT_SECRETS, dotenv_values())\n",
    "\n",
    "    environment_secrets = getattr(get_api_key, ENVIRONMENT_SECRETS)\n",
    "\n",
    "    api_key = environment_secrets[key_name]\n",
    "    assert api_key != None\n",
    "    return api_key\n",
    "\n",
    "def create_agent_node[T](\n",
    "    chat_model: ChatOpenAI,\n",
    "    instructions: str,\n",
    "    tools: ToolExecutor | list[BaseTool],\n",
    "    state_schema: type[T]\n",
    "):\n",
    "    return create_react_agent(\n",
    "        chat_model,\n",
    "        tools\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    llama_3_paper_vectorstore = create_vectorstore(\n",
    "        PyMuPDFLoader(\"https://arxiv.org/pdf/2404.19553\").load()\n",
    "    )\n",
    "\n",
    "    rag_prompt = ChatPromptTemplate.from_template(\n",
    "        clean_multi_line(\n",
    "        \"\"\"\n",
    "        CONTEXT:\n",
    "        {context}\n",
    "\n",
    "        QUERY:\n",
    "        {query}\n",
    "\n",
    "        You are a helpful assistant. \n",
    "        Use the available context to answer the question. \n",
    "        If you can't answer the question, say you don't know.\n",
    "        \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    chat_model = ChatOpenAI(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        api_key=SecretStr(get_api_key(\"OPENAI_API_KEY\"))\n",
    "    )\n",
    "\n",
    "    get_query = itemgetter(\"query\")\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableParallel(\n",
    "            {\"context\": get_query | llama_3_paper_vectorstore, \"query\": get_query}\n",
    "        ) |\n",
    "        rag_prompt |\n",
    "        chat_model |\n",
    "        StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return rag_chain.invoke(\n",
    "        {\"query\": \"What does 'context' refer to in 'long context'?\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In the context of 'long context' as mentioned in the provided text, 'context' refers to a coherent text such as a book or a long paper. The term 'long context' implies that the text being referred to is extensive and requires analysis and aggregation of information from different locations within that text.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run\n",
    "output = None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    output = main()\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "\n",
    "def test1():\n",
    "    print(\n",
    "        clean_multi_line(\n",
    "            \"\"\"\n",
    "            ArithmeticError\n",
    "            Hello i am a multi\n",
    "            line\n",
    "            string\n",
    "            that mean that i have many\n",
    "            lines\n",
    "            \"\"\"\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suds_ai-13dqfAdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
