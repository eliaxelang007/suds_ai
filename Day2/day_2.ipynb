{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installations\n",
    "\n",
    "%pip install --upgrade pip -q\n",
    "%pip install numpy matplotlib pandas scipy -q\n",
    "# %pip install setuptools wandb -q\n",
    "\n",
    "%pip install openai python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King Lear's enemy is Regan, one of his daughters, who conspires against him along with her sister Goneril to strip him of his power and mistreat him.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "from openai import OpenAI\n",
    "from openai.types.chat import (\n",
    "    ChatCompletionMessage,\n",
    "    ChatCompletionSystemMessageParam,\n",
    "    ChatCompletionUserMessageParam,\n",
    "    ChatCompletionAssistantMessageParam,\n",
    "    ChatCompletionToolMessageParam,\n",
    "    ChatCompletionFunctionMessageParam,\n",
    "  )\n",
    "\n",
    "from openai.types.chat.completion_create_params import ResponseFormat\n",
    "from openai._types import NotGiven\n",
    "\n",
    "from aimakerspace.text_utils import TextFileLoader, CharacterTextSplitter\n",
    "from aimakerspace.vectordatabase import VectorDatabase\n",
    "\n",
    "# WANDB = False\n",
    "\n",
    "# if WANDB:\n",
    "#   from wandb.integration.openai import autolog\n",
    "#   autolog({\"project\": \"First RAG App\"})\n",
    "\n",
    "ai_client = OpenAI(api_key=dotenv_values(\"../.env\")[\"OPENAI_API_KEY\"])\n",
    "\n",
    "RawConversationMessage = ChatCompletionSystemMessageParam | ChatCompletionUserMessageParam | ChatCompletionAssistantMessageParam | ChatCompletionToolMessageParam | ChatCompletionFunctionMessageParam\n",
    "\n",
    "class Role(Enum):\n",
    "  System = \"system\"\n",
    "  User = \"user\"\n",
    "  Assistant = \"assistant\"\n",
    "  Tool = \"tool\"\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, order=True, slots=True)\n",
    "class Message():\n",
    "  role: Role\n",
    "  content: str\n",
    "\n",
    "  def into(self) -> RawConversationMessage:\n",
    "    return {\"role\": self.role.value, \"content\": self.content} # type:ignore\n",
    "\n",
    "  @classmethod\n",
    "  def from_raw(cls, raw: ChatCompletionMessage) -> \"Message\":\n",
    "    return cls(Role(raw.role), raw.content or \"\")\n",
    "\n",
    "def system(message: str) -> Message:\n",
    "  return Message(Role.System, message)\n",
    "\n",
    "def user(message: str) -> Message:\n",
    "  return Message(Role.User, message)\n",
    "\n",
    "def respond(messages: list[Message], response_format: ResponseFormat | NotGiven=NotGiven()) -> Message:\n",
    "  raw_messages = [message.into() for message in messages]\n",
    "\n",
    "  return Message.from_raw(\n",
    "    ai_client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=raw_messages,\n",
    "      response_format=response_format\n",
    "    ).choices[0].message\n",
    "  )\n",
    "\n",
    "from dataclasses import field\n",
    "\n",
    "@dataclass(slots=True)\n",
    "class Chatbot:\n",
    "    messages: list[Message] = field(default_factory=list)\n",
    "\n",
    "    def respond(self, response_format: ResponseFormat | NotGiven=NotGiven()) -> Message:\n",
    "        response = respond(self.messages, response_format = response_format)\n",
    "        self.messages.append(response)\n",
    "        return response\n",
    "\n",
    "    def converse(self, chat: Message, response_format: ResponseFormat | NotGiven=NotGiven()) -> Message:\n",
    "        self.messages.append(chat)\n",
    "        return self.respond(response_format=response_format)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    king_lear_text = TextFileLoader(\"./data/KingLear.txt\")\n",
    "    documents: list[str] = king_lear_text.load_documents()\n",
    "\n",
    "    splitter = CharacterTextSplitter()\n",
    "    chunks = splitter.split_texts(documents)\n",
    "\n",
    "    database = await VectorDatabase().abuild_from_list(chunks)\n",
    "\n",
    "    king_lear_expert = Chatbot(\n",
    "        [\n",
    "            system(\n",
    "    \"\"\"\n",
    "    You will be given context and a query. Use the context to answer the query.\n",
    "    If you do not know the answer or there's no provided context, respond with \"I don't know\".\n",
    "    \"\"\"\n",
    "    )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    question = \"Who is King Lear's enemy?\"\n",
    "\n",
    "    matching_chunks = database.search_by_text(question, k=4)\n",
    "    context = \"\\n\".join((context[0] for context in matching_chunks))\n",
    "\n",
    "    response = king_lear_expert.converse(\n",
    "        user(\n",
    "    f\"\"\"\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Query:\n",
    "    {question}\n",
    "    \"\"\"\n",
    "        )\n",
    "    ).content\n",
    "\n",
    "    print(response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suds_ai-TmJupkLh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
