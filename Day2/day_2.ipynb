{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installations\n",
    "\n",
    "%pip install --upgrade pip -q\n",
    "%pip install mypy -q\n",
    "\n",
    "%pip install numpy matplotlib pandas scipy -q\n",
    "# %pip install setuptools wandb -q\n",
    "\n",
    "%pip install openai python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aimakerspace.text_utils import TextFileLoader, CharacterTextSplitter\n",
    "\n",
    "king_lear_text = TextFileLoader(\"./data/KingLear.txt\")\n",
    "documents = king_lear_text.load_documents()\n",
    "\n",
    "splitter = CharacterTextSplitter()\n",
    "chunks = splitter.split_texts(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aimakerspace.vectordatabase import VectorDatabase\n",
    "\n",
    "database = await VectorDatabase().abuild_from_list(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "from openai import OpenAI\n",
    "from openai.types.chat import (\n",
    "    ChatCompletionMessage,\n",
    "    ChatCompletionSystemMessageParam,\n",
    "    ChatCompletionUserMessageParam,\n",
    "    ChatCompletionAssistantMessageParam,\n",
    "    ChatCompletionToolMessageParam,\n",
    "    ChatCompletionFunctionMessageParam,\n",
    "  )\n",
    "\n",
    "from openai.types.chat.completion_create_params import ResponseFormat\n",
    "from openai._types import NotGiven\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# WANDB = False\n",
    "\n",
    "# if WANDB:\n",
    "#   from wandb.integration.openai import autolog\n",
    "#   autolog({\"project\": \"First RAG App\"})\n",
    "\n",
    "ai_client = OpenAI(api_key=dotenv_values(\"../.env\")[\"OPENAI_API_KEY\"])\n",
    "\n",
    "RawConversationMessage = ChatCompletionSystemMessageParam | ChatCompletionUserMessageParam | ChatCompletionAssistantMessageParam | ChatCompletionToolMessageParam | ChatCompletionFunctionMessageParam\n",
    "\n",
    "class Role(Enum):\n",
    "  System = \"system\"\n",
    "  User = \"user\"\n",
    "  Assistant = \"assistant\"\n",
    "  Tool = \"tool\"\n",
    "\n",
    "@dataclass(frozen=True, order=True, slots=True)\n",
    "class Message():\n",
    "  role: Role\n",
    "  content: str\n",
    "\n",
    "  def into(self) -> RawConversationMessage:\n",
    "    return {\"role\": self.role.value, \"content\": self.content} # type:ignore\n",
    "\n",
    "  @classmethod\n",
    "  def from_raw(cls, raw: ChatCompletionMessage) -> \"Message\":\n",
    "    return cls(Role(raw.role), raw.content or \"\")\n",
    "\n",
    "def system(message: str) -> Message:\n",
    "  return Message(Role.System, message)\n",
    "\n",
    "def user(message: str) -> Message:\n",
    "  return Message(Role.User, message)\n",
    "\n",
    "def respond(messages: list[Message], response_format: ResponseFormat | NotGiven=NotGiven()) -> Message:\n",
    "  raw_messages = [message.into() for message in messages]\n",
    "\n",
    "  return Message.from_raw(\n",
    "    ai_client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=raw_messages,\n",
    "      response_format=response_format\n",
    "    ).choices[0].message\n",
    "  )\n",
    "\n",
    "from dataclasses import field\n",
    "\n",
    "@dataclass(slots=True)\n",
    "class Chatbot:\n",
    "    messages: list[Message] = field(default_factory=list)\n",
    "\n",
    "    def respond(self, response_format: ResponseFormat | NotGiven=NotGiven()) -> Message:\n",
    "        response = respond(self.messages, response_format = response_format)\n",
    "        self.messages.append(response)\n",
    "        return response\n",
    "\n",
    "    def converse(self, chat: Message, response_format: ResponseFormat | NotGiven=NotGiven()) -> Message:\n",
    "        self.messages.append(chat)\n",
    "        return self.respond(response_format=response_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King Lear's enemies are his daughters, Goneril and Regan, who turn against him during the course of the play.\n"
     ]
    }
   ],
   "source": [
    "king_lear_expert = Chatbot(\n",
    "    [\n",
    "        system(\n",
    "\"\"\"\n",
    "You will be given context and a query. Use the context to answer the query.\n",
    "If you do not know the answer or there's no provided context, respond with \"I don't know\".\n",
    "\"\"\"\n",
    ")\n",
    "    ]\n",
    ")\n",
    "\n",
    "question = \"Who is King Lear's enemy?\"\n",
    "\n",
    "matching_chunks = database.search_by_text(question, k=4)\n",
    "context = \"\\n\".join((context[0] for context in matching_chunks))\n",
    "\n",
    "response = king_lear_expert.converse(\n",
    "    user(\n",
    "f\"\"\"\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Query:\n",
    "{question}\n",
    "\"\"\"\n",
    "    )\n",
    ").content\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suds_ai-TmJupkLh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
