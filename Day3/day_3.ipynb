{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip -q\n",
    "%pip install openai python-dotenv -q\n",
    "\n",
    "# %pip install mypy -q\n",
    "# %pip install numpy matplotlib pandas scipy -q\n",
    "# %pip install setuptools wandb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Any, Protocol, Concatenate\n",
    "from functools import wraps\n",
    "from contextlib import contextmanager\n",
    "from inspect import signature\n",
    "\n",
    "class OpenAiResource(Protocol):\n",
    "  @property\n",
    "  def id(self) -> str: ...\n",
    "\n",
    "class DeletedOpenAiResource(Protocol):\n",
    "  @property\n",
    "  def id(self) -> str: ...\n",
    "\n",
    "  @property\n",
    "  def deleted(self) -> bool: ...\n",
    "\n",
    "  @property\n",
    "  def object(self) -> str: ...\n",
    "\n",
    "\n",
    "def ignore_unknown_keyword_args(function: Callable[..., Any]) -> Callable[..., Any]:\n",
    "  @wraps(function)\n",
    "  def wrapped(*args: Any, **kwargs: Any):\n",
    "    parameter_names = set(signature(function).parameters.keys())\n",
    "\n",
    "    new_arguments = {\n",
    "      argument_name: argument_value for \n",
    "      (argument_name, argument_value) in \n",
    "      kwargs.items() if \n",
    "      argument_name in parameter_names\n",
    "    }\n",
    "\n",
    "    return function(*args, **new_arguments)\n",
    "  \n",
    "  return wrapped\n",
    "\n",
    "@contextmanager\n",
    "def use_openai_resource(resource: OpenAiResource, deleter: Callable[Concatenate[str, ...], DeletedOpenAiResource]):\n",
    "  try:\n",
    "    yield resource\n",
    "  finally:\n",
    "    ignore_unknown_keyword_args(deleter)(resource.id, _resource=resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The first words Victor Frankenstein speaks in the book are: \"That is also my victim!\"【4:0†source】."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What is the first words Victor Frankenstein speaks?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "from openai import OpenAI\n",
    "\n",
    "from openai.types.beta.vector_stores.vector_store_file import VectorStoreFile\n",
    "from openai.types.beta.vector_stores.vector_store_file_deleted import VectorStoreFileDeleted\n",
    "from openai.types.beta.threads.text_content_block import TextContentBlock\n",
    "\n",
    "from asyncio import sleep\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# WANDB = False\n",
    "\n",
    "# if WANDB:\n",
    "#   from wandb.integration.openai import autolog\n",
    "#   autolog({\"project\": \"First RAG App\"})\n",
    "\n",
    "client = OpenAI(api_key=dotenv_values(\"../.env\")[\"OPENAI_API_KEY\"])\n",
    "beta = client.beta\n",
    "\n",
    "async def main():\n",
    "  def vector_store_file_deleter(id: str, _resource: VectorStoreFile) -> VectorStoreFileDeleted:\n",
    "    return beta.vector_stores.files.delete(id, vector_store_id=_resource.vector_store_id)\n",
    "\n",
    "  with (\n",
    "    use_openai_resource(\n",
    "      client.files.create(\n",
    "        file=open(\"./frankenstien.txt\", \"rb\"),\n",
    "        purpose=\"assistants\"\n",
    "      ), \n",
    "      client.files.delete\n",
    "    ) as frankenstien_file,\n",
    "    use_openai_resource(\n",
    "      beta.vector_stores.create(\n",
    "          name=\"Frankenstien Documents\"\n",
    "      ),\n",
    "      beta.vector_stores.delete\n",
    "    ) as processed_documents,\n",
    "    use_openai_resource(\n",
    "      beta.vector_stores.files.create(\n",
    "        vector_store_id=processed_documents.id,\n",
    "        file_id=frankenstien_file.id\n",
    "      ),\n",
    "      vector_store_file_deleter\n",
    "    ),\n",
    "    use_openai_resource(\n",
    "      beta.assistants.create(\n",
    "          name=\"Frank(enstien)\",\n",
    "          instructions=\"\"\"\n",
    "      You are a librarian who'd like to answer questions about the book Frankenstien by Mary Shelley.\n",
    "      The book is included in a file for your reference; \n",
    "      when you answer, cite the chapter, page number, and paragraph in the book and explain why you're correct.\n",
    "      If you don't know the answer, say so.\n",
    "      \"\"\",\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          tools=[{\"type\": \"file_search\"}],\n",
    "          tool_resources={\"file_search\": {\"vector_store_ids\": [processed_documents.id]}}\n",
    "      ),\n",
    "      beta.assistants.delete\n",
    "    ) as assistant,\n",
    "    use_openai_resource(\n",
    "      beta.threads.create(),\n",
    "      beta.threads.delete\n",
    "    ) as thread\n",
    "  ):  \n",
    "    _message = beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=f\"What is the first words Victor Frankenstein speaks?\"\n",
    "    )\n",
    "\n",
    "    run = beta.threads.runs.create(\n",
    "      thread_id=thread.id,\n",
    "      assistant_id=assistant.id,\n",
    "    )\n",
    "\n",
    "    while run.status == \"in_progress\" or run.status == \"queued\":\n",
    "      await sleep(0)\n",
    "      run = beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "      )\n",
    "\n",
    "    messages = beta.threads.messages.list(\n",
    "      thread_id=thread.id\n",
    "    )\n",
    "\n",
    "    for message in messages:\n",
    "      for content_chunk in message.content:\n",
    "        match content_chunk:\n",
    "          case TextContentBlock() as text_content:\n",
    "            display(Markdown(text_content.text.value))\n",
    "          \n",
    "          case _:\n",
    "            display(Markdown(\"### Unsupported content chunk!\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suds_ai-TmJupkLh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
