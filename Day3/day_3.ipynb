{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installations\n",
    "\n",
    "%pip install --upgrade pip -q\n",
    "%pip install mypy -q\n",
    "\n",
    "# %pip install numpy matplotlib pandas scipy -q\n",
    "# %pip install setuptools wandb -q\n",
    "\n",
    "%pip install openai python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/63142182/to-what-extent-does-google-colab-support-python-typing\n",
    "\n",
    "from IPython.core.magic import register_cell_magic\n",
    "from IPython import get_ipython\n",
    "from mypy import api\n",
    "\n",
    "@register_cell_magic\n",
    "def mypy(line, cell):\n",
    "  for output in api.run(['-c', '\\n' + cell] + line.split()):\n",
    "    if output and not output.startswith('Success'):\n",
    "      raise TypeError(output)\n",
    "\n",
    "  get_ipython().run_cell(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "\n",
    "from openai import OpenAI\n",
    "from openai.types.chat import (\n",
    "    ChatCompletionMessage,\n",
    "    ChatCompletionSystemMessageParam,\n",
    "    ChatCompletionUserMessageParam,\n",
    "    ChatCompletionAssistantMessageParam,\n",
    "    ChatCompletionToolMessageParam,\n",
    "    ChatCompletionFunctionMessageParam,\n",
    "  )\n",
    "\n",
    "from openai.types.chat.completion_create_params import ResponseFormat\n",
    "from openai._types import NotGiven\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# WANDB = False\n",
    "\n",
    "# if WANDB:\n",
    "#   from wandb.integration.openai import autolog\n",
    "#   autolog({\"project\": \"First RAG App\"})\n",
    "\n",
    "client = OpenAI(api_key=dotenv_values(\"../.env\")[\"OPENAI_API_KEY\"])\n",
    "\n",
    "RawConversationMessage = ChatCompletionSystemMessageParam | ChatCompletionUserMessageParam | ChatCompletionAssistantMessageParam | ChatCompletionToolMessageParam | ChatCompletionFunctionMessageParam\n",
    "\n",
    "class Role(Enum):\n",
    "  System = \"system\"\n",
    "  User = \"user\"\n",
    "  Assistant = \"assistant\"\n",
    "  Tool = \"tool\"\n",
    "\n",
    "class AiModel(Enum):\n",
    "  Gpt3_5Turbo = \"gpt-3.5-turbo\"\n",
    "\n",
    "class AssistantTool(Enum):\n",
    "   CodeInterpreter = \"code_interpreter\"\n",
    "   FileSearch = \"file_search\"\n",
    "   Function = \"function\"\n",
    "\n",
    "@dataclass(frozen=True, order=True, slots=True)\n",
    "class Message():\n",
    "  role: Role\n",
    "  content: str\n",
    "\n",
    "  def into(self) -> RawConversationMessage:\n",
    "    return {\"role\": self.role.value, \"content\": self.content} # type:ignore\n",
    "\n",
    "  @classmethod\n",
    "  def from_raw(cls, raw: ChatCompletionMessage) -> \"Message\":\n",
    "    return cls(Role(raw.role), raw.content or \"\")\n",
    "\n",
    "def system(message: str) -> Message:\n",
    "  return Message(Role.System, message)\n",
    "\n",
    "def user(message: str) -> Message:\n",
    "  return Message(Role.User, message)\n",
    "\n",
    "def respond(messages: list[Message], response_format: ResponseFormat | NotGiven=NotGiven(), model: AiModel = AiModel.Gpt3_5Turbo) -> Message:\n",
    "  raw_messages = [message.into() for message in messages]\n",
    "\n",
    "  return Message.from_raw(\n",
    "    client.chat.completions.create(\n",
    "      model=model.value,\n",
    "      messages=raw_messages,\n",
    "      response_format=response_format\n",
    "    ).choices[0].message\n",
    "  )\n",
    "\n",
    "@dataclass(slots=True)\n",
    "class Chatbot:\n",
    "    messages: list[Message] = field(default_factory=list)\n",
    "\n",
    "    def respond(self, response_format: ResponseFormat | NotGiven=NotGiven()) -> Message:\n",
    "        response = respond(self.messages, response_format = response_format)\n",
    "        self.messages.append(response)\n",
    "        return response\n",
    "\n",
    "    def converse(self, chat: Message, response_format: ResponseFormat | NotGiven=NotGiven()) -> Message:\n",
    "        self.messages.append(chat)\n",
    "        return self.respond(response_format=response_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queued\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "SyncCursorPage[Message](data=[Message(id='msg_QAhSfbhQKO42FVpqXlFOthUY', assistant_id='asst_8AdQfwoHc1q2WoXurPu4r9Ov', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[FileCitationAnnotation(end_index=407, file_citation=FileCitation(file_id='file-LsiTe1nwVdzfrKgrlWkqnmRN'), start_index=395, text='【4:2†source】', type='file_citation')], value='The first words spoken by Victor Frankenstein in the book \"Frankenstein\" by Mary Shelley are, \"Cursed be the day, abhorred devil, in which you first saw light! Cursed (although I curse myself) be the hands that formed you! You have made me wretched beyond expression. You have left me no power to consider whether I am just to you or not. Begone! Relieve me from the sight of your detested form\"【4:2†source】.'), type='text')], created_at=1722303860, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_GuyBTi7rtWCLZ38ORzmMqyOe', status=None, thread_id='thread_boIVxNC8FOBEhVj7UjkHmIZ1'), Message(id='msg_y3RXYaFd70sqlGLW4tr83GZ9', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='What is the first words Victor Frankenstein speaks?'), type='text')], created_at=1722303857, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_boIVxNC8FOBEhVj7UjkHmIZ1')], object='list', first_id='msg_QAhSfbhQKO42FVpqXlFOthUY', last_id='msg_y3RXYaFd70sqlGLW4tr83GZ9', has_more=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[Message](data=[Message(id='msg_QAhSfbhQKO42FVpqXlFOthUY', assistant_id='asst_8AdQfwoHc1q2WoXurPu4r9Ov', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[FileCitationAnnotation(end_index=407, file_citation=FileCitation(file_id='file-LsiTe1nwVdzfrKgrlWkqnmRN'), start_index=395, text='【4:2†source】', type='file_citation')], value='The first words spoken by Victor Frankenstein in the book \"Frankenstein\" by Mary Shelley are, \"Cursed be the day, abhorred devil, in which you first saw light! Cursed (although I curse myself) be the hands that formed you! You have made me wretched beyond expression. You have left me no power to consider whether I am just to you or not. Begone! Relieve me from the sight of your detested form\"【4:2†source】.'), type='text')], created_at=1722303860, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_GuyBTi7rtWCLZ38ORzmMqyOe', status=None, thread_id='thread_boIVxNC8FOBEhVj7UjkHmIZ1'), Message(id='msg_y3RXYaFd70sqlGLW4tr83GZ9', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='What is the first words Victor Frankenstein speaks?'), type='text')], created_at=1722303857, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_boIVxNC8FOBEhVj7UjkHmIZ1')], object='list', first_id='msg_QAhSfbhQKO42FVpqXlFOthUY', last_id='msg_y3RXYaFd70sqlGLW4tr83GZ9', has_more=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import sleep\n",
    "from pprint import pprint\n",
    "\n",
    "frankenstien_file = client.files.create(\n",
    "    file=open(\"./frankenstien.txt\", \"rb\"),\n",
    "    purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "processed_documents = client.beta.vector_stores.create(\n",
    "    name=\"Frankenstien Documents\"\n",
    ")\n",
    "\n",
    "vector_store_file = client.beta.vector_stores.files.create(\n",
    "  vector_store_id=processed_documents.id,\n",
    "  file_id=frankenstien_file.id\n",
    ")\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Frank(enstien)\",\n",
    "    instructions=\"\"\"\n",
    "You are a librarian who'd like to answer questions about the book Frankenstien by Mary Shelley.\n",
    "The book is included in a file for your reference; \n",
    "when you answer, you cite your source in the book and explain why you're correct.\n",
    "If you don't know the answer, say so.\n",
    "\"\"\",\n",
    "    model=AiModel.Gpt3_5Turbo.value,\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    "    tool_resources={\"file_search\": {\"vector_store_ids\": [processed_documents.id]}}\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=f\"What is the first words Victor Frankenstein speaks?\"\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    ")\n",
    "\n",
    "# Wait for Run to Complete\n",
    "while run.status == \"in_progress\" or run.status == \"queued\":\n",
    "  sleep(1)\n",
    "  print(run.status)\n",
    "  run = client.beta.threads.runs.retrieve(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    "  )\n",
    "\n",
    "# Collect Messages from the Thread\n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "client.beta.assistants.delete(assistant.id)\n",
    "client.beta.vector_stores.delete(processed_documents.id)\n",
    "client.files.delete(frankenstien_file.id)\n",
    "client.beta.threads.delete(thread.id)\n",
    "\n",
    "pprint(messages)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "A = str | int\n",
    "A = Literal[\"asdf\"] | Literal[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from typing import Literal, Union\n",
    "from types import FunctionType, NoneType\n",
    "\n",
    "def get_temperature(location: str, unit: Literal[\"celsius\"] | Literal[\"farenheit\"] = \"celsius\") -> str:\n",
    "    \"\"\"\n",
    "    Get the current temperature at a specified location.\n",
    "    \"\"\"\n",
    "    \n",
    "    return f\"Weather: {location}:{unit}\"\n",
    "    \n",
    "def non_annotated(a: Literal[None] | Literal[123]) -> str:\n",
    "    \"asdf\"\n",
    "    return None\n",
    "\n",
    "def to_openai_tool(function: FunctionType):\n",
    "    parameters = getattr(function, \"__annotations__\", None)\n",
    "    \n",
    "    assert parameters != None and len(parameters) != 0, \"The function must have type annotations to generate tool data!\"\n",
    "    assert parameters.pop(\"return\") == str, \"The return type of the function must be a string!\" \n",
    "    \n",
    "    def type_to_json_schema(parameter_type):\n",
    "        SCHEMA_TYPE_MAPPING = {\n",
    "            str: \"string\",\n",
    "            int: \"number\",\n",
    "            float: \"number\",\n",
    "            dict: \"object\",\n",
    "            list: \"array\",\n",
    "            bool: \"boolean\",\n",
    "            None: \"null\"\n",
    "        }\n",
    "        \n",
    "        schema_type = SCHEMA_TYPE_MAPPING.get(parameter_type, None)\n",
    "        \n",
    "        if schema_type != None:\n",
    "            return {\"type\": schema_type}\n",
    "        \n",
    "        error_message = f\"Unconvertable type annotation [{parameter_type}]\"\n",
    "        \n",
    "        maybe_union_type = getattr(parameter_type, \"__origin__\", None)\n",
    "        assert maybe_union_type != None and maybe_union_type == Union, error_message\n",
    "        \n",
    "        def parse_argument(argument):\n",
    "            maybe_argument_type = getattr(argument, \"__origin__\", None)\n",
    "            assert maybe_argument_type != None and maybe_argument_type == Literal, error_message \n",
    "            \n",
    "            maybe_single_argument = argument.__args__\n",
    "            \n",
    "            assert len(maybe_single_argument) == 1, error_message\n",
    "            \n",
    "            return maybe_single_argument[0]\n",
    "        \n",
    "        arguments = [parse_argument(argument) for argument in parameter_type.__args__]\n",
    "        \n",
    "        def parse_argument_type(argument):\n",
    "            argument_type = type(argument)\n",
    "            \n",
    "            if argument_type != NoneType:\n",
    "                assert SCHEMA_TYPE_MAPPING.get(argument_type, None) != None, error_message\n",
    "            \n",
    "            return argument_type\n",
    "        \n",
    "        argument_types = [parse_argument_type(argument) for argument in arguments]\n",
    "        \n",
    "        enum_type = {\"enum\": arguments}\n",
    "        \n",
    "        arguments_type_iter = iter(argument_types)\n",
    "        first_argument_type = next(arguments_type_iter)\n",
    "        \n",
    "        if all((first_argument_type == argument_type for argument_type in argument_types)):\n",
    "            enum_type.update(type_to_json_schema(first_argument_type))\n",
    "        \n",
    "        return enum_type\n",
    "    \n",
    "    parameters = {\n",
    "        parameter_name: type_to_json_schema(parameter_type) for \n",
    "        parameter_name, parameter_type in parameters.items()\n",
    "    }\n",
    "    \n",
    "    description = getattr(function, \"__doc__\", None)\n",
    "    \n",
    "    assert description != None, \"The function must have a docstring!\"\n",
    "    \n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": function.__name__,\n",
    "            \"description\": description.strip(),\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": parameters\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "pprint(to_openai_tool(non_annotated))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suds_ai-TmJupkLh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
